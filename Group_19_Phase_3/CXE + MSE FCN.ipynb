{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gggcpfBwQcU8"
   },
   "source": [
    "## Combined CXE + MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RVi2nqr-A4xK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z3w2sce8WXYa"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GxDchYyEo5Fe"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import random\n",
    "from os import listdir\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LKDooY69A4xO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYMYVmxMpX2z",
    "outputId": "6d223697-ed45-4d82-fd14-0dc185e21864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FBchPi4jvHMj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vamBkzek_ZfR"
   },
   "source": [
    "## Creating directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating directories for test and train data set\n",
    "dataset_home = 'cat_vs_dog/'\n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs:\n",
    "\t# create label subdirectories\n",
    "\tlabeldirs = ['dogs/', 'cats/']\n",
    "\tfor labldir in labeldirs:\n",
    "\t\tnewdir = dataset_home + subdir + labldir\n",
    "\t\tmakedirs(newdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Source</th>\n",
       "      <th>LabelName</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>XMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMin</th>\n",
       "      <th>YMax</th>\n",
       "      <th>IsOccluded</th>\n",
       "      <th>IsTruncated</th>\n",
       "      <th>...</th>\n",
       "      <th>IsDepiction</th>\n",
       "      <th>IsInside</th>\n",
       "      <th>XClick1X</th>\n",
       "      <th>XClick2X</th>\n",
       "      <th>XClick3X</th>\n",
       "      <th>XClick4X</th>\n",
       "      <th>XClick1Y</th>\n",
       "      <th>XClick2Y</th>\n",
       "      <th>XClick3Y</th>\n",
       "      <th>XClick4Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b9fcba019d36</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636250</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.661667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cb13febe0138</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410882</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.999062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005a9520eb22c19</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.226296</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.305942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006303f02219b07</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508594</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375294</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.998824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00064d23bf997652</td>\n",
       "      <td>xclick</td>\n",
       "      <td>/m/0bt9lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678038</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.694286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  Source  LabelName  Confidence      XMin      XMax  \\\n",
       "0  0000b9fcba019d36  xclick  /m/0bt9lr           1  0.165000  0.903750   \n",
       "1  0000cb13febe0138  xclick  /m/0bt9lr           1  0.000000  0.651875   \n",
       "2  0005a9520eb22c19  xclick  /m/0bt9lr           1  0.094167  0.611667   \n",
       "3  0006303f02219b07  xclick  /m/0bt9lr           1  0.000000  0.999219   \n",
       "4  00064d23bf997652  xclick  /m/0bt9lr           1  0.240938  0.906183   \n",
       "\n",
       "       YMin      YMax  IsOccluded  IsTruncated  ...  IsDepiction  IsInside  \\\n",
       "0  0.268333  0.998333           1            1  ...            0         0   \n",
       "1  0.000000  0.999062           1            1  ...            0         0   \n",
       "2  0.055626  0.998736           1            1  ...            0         0   \n",
       "3  0.000000  0.998824           1            1  ...            0         0   \n",
       "4  0.000000  0.694286           0            0  ...            0         0   \n",
       "\n",
       "   XClick1X  XClick2X  XClick3X  XClick4X  XClick1Y  XClick2Y  XClick3Y  \\\n",
       "0  0.636250  0.903750  0.748750  0.165000  0.268333  0.506667  0.998333   \n",
       "1  0.312500  0.000000  0.317500  0.651875  0.000000  0.410882  0.999062   \n",
       "2  0.487500  0.611667  0.243333  0.094167  0.055626  0.226296  0.998736   \n",
       "3  0.508594  0.999219  0.000000  0.478906  0.000000  0.375294  0.720000   \n",
       "4  0.678038  0.906183  0.240938  0.522388  0.000000  0.370000  0.424286   \n",
       "\n",
       "   XClick4Y  \n",
       "0  0.661667  \n",
       "1  0.999062  \n",
       "2  0.305942  \n",
       "3  0.998824  \n",
       "4  0.694286  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the csv file\n",
    "df = pd.read_csv(\"cadod.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.LabelName.replace({'/m/01yrx':'cat', '/m/0bt9lr':'dog'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_list = df[df.LabelName == 'dog']['ImageID']\n",
    "cat_list = df[df.LabelName == 'cat']['ImageID']\n",
    "#list(dog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_test = []\n",
    "file_name_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# moving images to test and train folder\n",
    "\n",
    "random.seed(10)\n",
    "# define ratio of pictures to use for test\n",
    "test_ratio = 0.20\n",
    "count_c = 0\n",
    "count_d = 0\n",
    "\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'cadod/'\n",
    "for file in listdir(src_directory):\n",
    "    #print(file.replace('.jpg','').replace('._','') in list(cat_list))\n",
    "    #print(file.replace('.jpg','').replace('._','') in list(dog_list))\n",
    "    src = src_directory + '/' + file\n",
    "    dst_dir = 'train/'\n",
    "    if random.random() < test_ratio:\n",
    "        dst_dir = 'test/'\n",
    "        file_name_test.append(file.replace('.jpg','').replace('._',''))\n",
    "    if file.replace('.jpg','').replace('._','') in list(cat_list) and count_c < 500:\n",
    "        dst = dataset_home + dst_dir + 'cats/'  + file\n",
    "        count_c +=1\n",
    "        copyfile(src, dst)\n",
    "        file_name_train.append(file.replace('.jpg','').replace('._',''))\n",
    "    elif file.replace('.jpg','').replace('._','') in list(dog_list) and count_d < 500:\n",
    "        dst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "        count_d +=1\n",
    "        copyfile(src, dst)\n",
    "        file_name_train.append(file.replace('.jpg','').replace('._',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b55a824f4a375d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc26925fd646efe5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f8fccbefa2e8e33f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9c730899f38007cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01901b6370020f3c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID\n",
       "0  2b55a824f4a375d3\n",
       "1  bc26925fd646efe5\n",
       "2  f8fccbefa2e8e33f\n",
       "3  9c730899f38007cc\n",
       "4  01901b6370020f3c"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id = pd.DataFrame (file_name_train, columns = ['ImageID'])\n",
    "train_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d00eb685487904b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ddfc5237d20952a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e60d548f2f124a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4add7bb2ee11f8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8054527db8754ab1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID\n",
       "0  d00eb685487904b0\n",
       "1  ddfc5237d20952a7\n",
       "2  e60d548f2f124a01\n",
       "3  f4add7bb2ee11f8d\n",
       "4  8054527db8754ab1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = pd.DataFrame (file_name_test, columns = ['ImageID'])\n",
    "test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID_left</th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b9fcba019d36</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.998333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cb13febe0138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.999062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005a9520eb22c19</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.998736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006303f02219b07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.998824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00064d23bf997652</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.694286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageID_left      XMin      YMin      XMax      YMax\n",
       "0  0000b9fcba019d36  0.165000  0.268333  0.903750  0.998333\n",
       "1  0000cb13febe0138  0.000000  0.000000  0.651875  0.999062\n",
       "2  0005a9520eb22c19  0.094167  0.055626  0.611667  0.998736\n",
       "3  0006303f02219b07  0.000000  0.000000  0.999219  0.998824\n",
       "4  00064d23bf997652  0.240938  0.000000  0.906183  0.694286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ImageID.astype('O')\n",
    "train_id.ImageID.astype('O')\n",
    "df_n = df[['ImageID','XMin', 'YMin', 'XMax', 'YMax']]\n",
    "df_n.set_index('ImageID')\n",
    "train_id.set_index('ImageID')\n",
    "train_id_n = df_n.join(train_id, how = 'left', lsuffix = '_left', rsuffix = '_right')\n",
    "train_id_n.drop(columns = ['ImageID_right'], inplace = True)\n",
    "train_id_n.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID_left</th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000b9fcba019d36</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.998333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cb13febe0138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.999062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005a9520eb22c19</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.998736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006303f02219b07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.998824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00064d23bf997652</td>\n",
       "      <td>0.240938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>0.694286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageID_left      XMin      YMin      XMax      YMax\n",
       "0  0000b9fcba019d36  0.165000  0.268333  0.903750  0.998333\n",
       "1  0000cb13febe0138  0.000000  0.000000  0.651875  0.999062\n",
       "2  0005a9520eb22c19  0.094167  0.055626  0.611667  0.998736\n",
       "3  0006303f02219b07  0.000000  0.000000  0.999219  0.998824\n",
       "4  00064d23bf997652  0.240938  0.000000  0.906183  0.694286"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ImageID.astype('O')\n",
    "test_id.ImageID.astype('O')\n",
    "#df.set_index('ImageID')\n",
    "test_id.set_index('ImageID')\n",
    "test_id_n = df_n.join(test_id, how = 'left', lsuffix = '_left', rsuffix = '_right')\n",
    "test_id_n.drop(columns = ['ImageID_right'], inplace = True)\n",
    "test_id_n.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                               \"Train Loss\", \n",
    "                               \"Valid Loss\",\n",
    "                               \"Test Loss\",\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3WWNZkQ_ZfS"
   },
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    #transforms.ToPILImage(),             \n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "transform_train = transforms.Compose([\n",
    "    #transforms.ToPILImage(),             \n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    #transforms.RandomAutocontrast()\n",
    "    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_it = datasets.ImageFolder('cat_vs_dog/train/', transform=transform_train)\n",
    "test_it = datasets.ImageFolder('cat_vs_dog/test/', transform=transform_test)\n",
    "\n",
    "dataset_size = len(train_it)\n",
    "dataset_indices = list(range(dataset_size))\n",
    "np.random.shuffle(dataset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cats', 1: 'dogs'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2class = {v: k for k, v in train_it.class_to_idx.items()}\n",
    "idx2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(train_it)\n",
    "dataset_indices = list(range(dataset_size))\n",
    "#dataset_indices[val_split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split_index = int(np.floor(0.2 * dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 16\n",
    "bs_test = 4\n",
    "bs_valid = 8\n",
    "trainloader = DataLoader(dataset=train_it, shuffle=False, batch_size=bs_train, sampler=train_sampler)\n",
    "valloader = DataLoader(dataset=train_it, shuffle=False, batch_size=bs_valid, sampler=val_sampler)\n",
    "testloader = DataLoader(test_it, batch_size=bs_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_box_train = train_id_n[val_split_index:]\n",
    "y_box_val =  train_id_n[:val_split_index]\n",
    "y_box_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9lp4ZSAKysZ",
    "outputId": "368d2bbf-79dd-4288-8c4d-73b0facaad70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 128, 128]) torch.Size([16])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in trainloader:\n",
    "    print(images.size(), labels.size())\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "Agml0qpPCuuM",
    "outputId": "a3a68d08-b792-486e-b1a8-4bdd27e95e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 128, 128]) torch.Size([8])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in valloader:\n",
    "    print(images.size(), labels.size())\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('data/img.npy', allow_pickle=True)\n",
    "y_label = np.load('data/y_label.npy', allow_pickle=True)\n",
    "y_bbox = np.load('data/y_bbox.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.from_numpy(y_box_train[['XMin', 'YMin', 'XMax', 'YMax']].to_numpy())\n",
    "y_val_tensor = torch.from_numpy(y_box_val[['XMin', 'YMin', 'XMax', 'YMax']].to_numpy())\n",
    "y_test_tensor = torch.from_numpy(test_id_n[['XMin', 'YMin', 'XMax', 'YMax']].to_numpy())\n",
    "#y_val_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Wf1bzyE90L7g"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "#defining neural network layers\n",
    "class cadod_c(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(cadod_c, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d(0.1)\n",
    "        self.fc1 = nn.Linear(18000, 400)\n",
    "        self.fc2 = nn.Linear(400, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model_c = cadod_c()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_c.parameters(), lr=0.0002, weight_decay = 3e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [500,1000,1500], gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression neural network\n",
    "class cadod_r(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=14*14*16, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc5 = nn.Linear(in_features=32, out_features=4) \n",
    "\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = nn.Flatten()(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "       \n",
    "    \n",
    "        x = F.relu(self.fc3(x))\n",
    "       \n",
    "        r = self.fc5(x)\n",
    "       \n",
    "        return r\n",
    "    \n",
    "model_r = cadod_r()\n",
    "# MSE loss scaffolding layer\n",
    "loss_fn = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model_r.parameters(), lr=0.0005, weight_decay = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_tag, dim = 1)    \n",
    "    correct_results_sum = (y_pred_tags == y_test).sum().float()    \n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0/50)\n",
      "Training loss : 0.7118749812245369\n",
      "Training accuracy : 49.35\n",
      "Validation loss : 0.7100486849900335\n",
      "Validation accuracy : 51.95\n",
      "Epoch(1/50)\n",
      "Training loss : 0.7090466111898422\n",
      "Training accuracy : 48.6\n",
      "Validation loss : 0.7075532027520239\n",
      "Validation accuracy : 51.75\n",
      "Epoch(2/50)\n",
      "Training loss : 0.7081201106309891\n",
      "Training accuracy : 52.5\n",
      "Validation loss : 0.704474622849375\n",
      "Validation accuracy : 51.9\n",
      "Epoch(3/50)\n",
      "Training loss : 0.7084089532494545\n",
      "Training accuracy : 49.725\n",
      "Validation loss : 0.7061632547527552\n",
      "Validation accuracy : 51.9\n",
      "Epoch(4/50)\n",
      "Training loss : 0.7080016046762466\n",
      "Training accuracy : 49.575\n",
      "Validation loss : 0.7052379011176526\n",
      "Validation accuracy : 51.9\n",
      "Epoch(5/50)\n",
      "Training loss : 0.7057248204946518\n",
      "Training accuracy : 50.7\n",
      "Validation loss : 0.705911069130525\n",
      "Validation accuracy : 51.9\n",
      "Epoch(6/50)\n",
      "Training loss : 0.706674014031887\n",
      "Training accuracy : 50.5\n",
      "Validation loss : 0.7070628259563818\n",
      "Validation accuracy : 51.7\n",
      "Epoch(7/50)\n",
      "Training loss : 0.7057572767138481\n",
      "Training accuracy : 50.35\n",
      "Validation loss : 0.7050061433576047\n",
      "Validation accuracy : 51.85\n",
      "Epoch(8/50)\n",
      "Training loss : 0.7090481474995614\n",
      "Training accuracy : 49.65\n",
      "Validation loss : 0.7057594538200647\n",
      "Validation accuracy : 51.8\n",
      "Epoch(9/50)\n",
      "Training loss : 0.7076527655124665\n",
      "Training accuracy : 52.475\n",
      "Validation loss : 0.7033122044522315\n",
      "Validation accuracy : 51.95\n",
      "Epoch(10/50)\n",
      "Training loss : 0.7071493312716484\n",
      "Training accuracy : 50.975\n",
      "Validation loss : 0.7040359573205933\n",
      "Validation accuracy : 52.55\n",
      "Epoch(11/50)\n",
      "Training loss : 0.7090287208557129\n",
      "Training accuracy : 48.8\n",
      "Validation loss : 0.7053229030687362\n",
      "Validation accuracy : 51.8\n",
      "Epoch(12/50)\n",
      "Training loss : 0.7080927088856697\n",
      "Training accuracy : 50.0\n",
      "Validation loss : 0.7084278791211546\n",
      "Validation accuracy : 51.75\n",
      "Epoch(13/50)\n",
      "Training loss : 0.7073122054338455\n",
      "Training accuracy : 50.775\n",
      "Validation loss : 0.7052912323735654\n",
      "Validation accuracy : 51.85\n",
      "Epoch(14/50)\n",
      "Training loss : 0.7102532595396042\n",
      "Training accuracy : 48.75\n",
      "Validation loss : 0.7062017263611778\n",
      "Validation accuracy : 51.2\n",
      "Epoch(15/50)\n",
      "Training loss : 0.7079784229397774\n",
      "Training accuracy : 52.15\n",
      "Validation loss : 0.703770897584036\n",
      "Validation accuracy : 52.25\n",
      "Epoch(16/50)\n",
      "Training loss : 0.7098743841052055\n",
      "Training accuracy : 49.025\n",
      "Validation loss : 0.7077040287898854\n",
      "Validation accuracy : 51.3\n",
      "Epoch(17/50)\n",
      "Training loss : 0.7076957255601883\n",
      "Training accuracy : 49.725\n",
      "Validation loss : 0.7041498473845422\n",
      "Validation accuracy : 51.75\n",
      "Epoch(18/50)\n",
      "Training loss : 0.7092839688062668\n",
      "Training accuracy : 48.275\n",
      "Validation loss : 0.7020973746664823\n",
      "Validation accuracy : 51.9\n",
      "Epoch(19/50)\n",
      "Training loss : 0.7069541826844216\n",
      "Training accuracy : 51.7\n",
      "Validation loss : 0.7059909645933657\n",
      "Validation accuracy : 51.75\n",
      "Epoch(20/50)\n",
      "Training loss : 0.7089877456426621\n",
      "Training accuracy : 49.5\n",
      "Validation loss : 0.7029033537954092\n",
      "Validation accuracy : 52.5\n",
      "Epoch(21/50)\n",
      "Training loss : 0.7093431070446968\n",
      "Training accuracy : 49.6\n",
      "Validation loss : 0.7053107283078134\n",
      "Validation accuracy : 51.85\n",
      "Epoch(22/50)\n",
      "Training loss : 0.7060155525803566\n",
      "Training accuracy : 51.25\n",
      "Validation loss : 0.706568481400609\n",
      "Validation accuracy : 51.85\n",
      "Epoch(23/50)\n",
      "Training loss : 0.7043239995837212\n",
      "Training accuracy : 51.325\n",
      "Validation loss : 0.7051448501180857\n",
      "Validation accuracy : 51.95\n",
      "Epoch(24/50)\n",
      "Training loss : 0.7063856944441795\n",
      "Training accuracy : 50.2\n",
      "Validation loss : 0.7046565556433052\n",
      "Validation accuracy : 51.95\n",
      "Epoch(25/50)\n",
      "Training loss : 0.7079715386033059\n",
      "Training accuracy : 50.35\n",
      "Validation loss : 0.7027813681401313\n",
      "Validation accuracy : 51.85\n",
      "Epoch(26/50)\n",
      "Training loss : 0.7046286404132843\n",
      "Training accuracy : 49.025\n",
      "Validation loss : 0.7050394255900756\n",
      "Validation accuracy : 52.6\n",
      "Epoch(27/50)\n",
      "Training loss : 0.7052292883396148\n",
      "Training accuracy : 51.75\n",
      "Validation loss : 0.7039080997928977\n",
      "Validation accuracy : 52.0\n",
      "Epoch(28/50)\n",
      "Training loss : 0.7064696460962295\n",
      "Training accuracy : 50.375\n",
      "Validation loss : 0.7067568204365671\n",
      "Validation accuracy : 51.8\n",
      "Epoch(29/50)\n",
      "Training loss : 0.7079446151852608\n",
      "Training accuracy : 50.425\n",
      "Validation loss : 0.7051233590114862\n",
      "Validation accuracy : 51.2\n",
      "Epoch(30/50)\n",
      "Training loss : 0.7054599434137344\n",
      "Training accuracy : 49.525\n",
      "Validation loss : 0.7058732388541102\n",
      "Validation accuracy : 51.85\n",
      "Epoch(31/50)\n",
      "Training loss : 0.7092289000749588\n",
      "Training accuracy : 49.9\n",
      "Validation loss : 0.7052725095767528\n",
      "Validation accuracy : 52.0\n",
      "Epoch(32/50)\n",
      "Training loss : 0.7073726713657379\n",
      "Training accuracy : 49.525\n",
      "Validation loss : 0.7045369705185294\n",
      "Validation accuracy : 51.8\n",
      "Epoch(33/50)\n",
      "Training loss : 0.7098496854305267\n",
      "Training accuracy : 47.875\n",
      "Validation loss : 0.703081227792427\n",
      "Validation accuracy : 51.9\n",
      "Epoch(34/50)\n",
      "Training loss : 0.705561313033104\n",
      "Training accuracy : 51.8\n",
      "Validation loss : 0.7062440622597933\n",
      "Validation accuracy : 51.9\n",
      "Epoch(35/50)\n",
      "Training loss : 0.7097637414932251\n",
      "Training accuracy : 51.225\n",
      "Validation loss : 0.7037342146970331\n",
      "Validation accuracy : 51.85\n",
      "Epoch(36/50)\n",
      "Training loss : 0.705867825448513\n",
      "Training accuracy : 52.825\n",
      "Validation loss : 0.7055256116203964\n",
      "Validation accuracy : 51.75\n",
      "Epoch(37/50)\n",
      "Training loss : 0.709127263724804\n",
      "Training accuracy : 46.75\n",
      "Validation loss : 0.7061041045933962\n",
      "Validation accuracy : 51.95\n",
      "Epoch(38/50)\n",
      "Training loss : 0.7112988963723182\n",
      "Training accuracy : 48.975\n",
      "Validation loss : 0.7055594420526177\n",
      "Validation accuracy : 51.85\n",
      "Epoch(39/50)\n",
      "Training loss : 0.7067484065890313\n",
      "Training accuracy : 51.0\n",
      "Validation loss : 0.7024275815114379\n",
      "Validation accuracy : 52.0\n",
      "Epoch(40/50)\n",
      "Training loss : 0.7071689069271088\n",
      "Training accuracy : 51.2\n",
      "Validation loss : 0.7050982115790247\n",
      "Validation accuracy : 52.05\n",
      "Epoch(41/50)\n",
      "Training loss : 0.7045126989483833\n",
      "Training accuracy : 51.1\n",
      "Validation loss : 0.7048486781772226\n",
      "Validation accuracy : 51.9\n",
      "Epoch(42/50)\n",
      "Training loss : 0.7085898339748382\n",
      "Training accuracy : 50.45\n",
      "Validation loss : 0.7029092389857396\n",
      "Validation accuracy : 51.8\n",
      "Epoch(43/50)\n",
      "Training loss : 0.7081213623285294\n",
      "Training accuracy : 49.525\n",
      "Validation loss : 0.7050800462719053\n",
      "Validation accuracy : 52.4\n",
      "Epoch(44/50)\n",
      "Training loss : 0.7069022133946419\n",
      "Training accuracy : 50.75\n",
      "Validation loss : 0.7027802959550172\n",
      "Validation accuracy : 52.45\n",
      "Epoch(45/50)\n",
      "Training loss : 0.7095731496810913\n",
      "Training accuracy : 48.55\n",
      "Validation loss : 0.7058138457126916\n",
      "Validation accuracy : 51.8\n",
      "Epoch(46/50)\n",
      "Training loss : 0.7088750466704369\n",
      "Training accuracy : 49.425\n",
      "Validation loss : 0.7031038623768836\n",
      "Validation accuracy : 51.95\n",
      "Epoch(47/50)\n",
      "Training loss : 0.7069298774003983\n",
      "Training accuracy : 49.1\n",
      "Validation loss : 0.70489386706613\n",
      "Validation accuracy : 51.75\n",
      "Epoch(48/50)\n",
      "Training loss : 0.7105465099215508\n",
      "Training accuracy : 48.3\n",
      "Validation loss : 0.705224594520405\n",
      "Validation accuracy : 53.2\n",
      "Epoch(49/50)\n",
      "Training loss : 0.7092552751302719\n",
      "Training accuracy : 48.9\n",
      "Validation loss : 0.7039555440656841\n",
      "Validation accuracy : 51.8\n"
     ]
    }
   ],
   "source": [
    "model_c = model_c.to(device)\n",
    "model_r = model_r.to(device)\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cum_epoch_loss = 0\n",
    "    cum_acc = 0\n",
    "    batch_loss = 0\n",
    "    mse_loss = 0\n",
    "    train = 0\n",
    "    test = 0\n",
    "    val = 0\n",
    "    model_c.train()\n",
    "    model_r.train()\n",
    "    #Training the model\n",
    "    for batch, (images, labels) in enumerate(trainloader,1):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #images_2 = images_2.to(device)\n",
    "        \n",
    "        bbox = y_train_tensor[train:train+bs_train].to(device)\n",
    "        train +=bs_train\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "        label_pred = model_c(images).squeeze()  #training the classifier model\n",
    "        box_pred = model_r(images)  #training the regressor model\n",
    "        loss_1 = criterion(label_pred, labels) #CXE loss\n",
    "        acc = binary_acc(label_pred, labels)\n",
    "        loss_2 = loss_fn(box_pred, torch.unsqueeze(bbox.float(), dim=1)) #MSE\n",
    "        loss = loss_1 + loss_2 #combined loss\n",
    "        loss.backward() #backpropagating loss\n",
    "        optimizer.step()  #gradient update\n",
    "        batch_loss += loss.item()\n",
    "        cum_acc += acc.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        #print(f'Epoch({e}/{num_epochs} : Batch number({batch}/{len(trainloader)})')\n",
    "    \n",
    "    #Evaluating the model on validation set\n",
    "    with torch.no_grad():\n",
    "        model_c.eval()\n",
    "        model_r.eval()\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        val = 0\n",
    "        for batch, (X_val_batch, y_val_batch) in enumerate(valloader,1):\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            y_box_val = y_val_tensor[val:val+bs_valid].to(device)\n",
    "            \n",
    "            y_val_pred = model_c(X_val_batch).squeeze()\n",
    "            y_box_pred = model_r(X_val_batch).squeeze()\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = binary_acc(y_val_pred, y_val_batch) \n",
    "            \n",
    "            mse_loss = loss_fn(y_box_pred, torch.unsqueeze(y_box_val.float(), dim=1))\n",
    "            \n",
    "            val_epoch_loss += val_loss.item() + mse_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "            val += bs_valid\n",
    "            \n",
    "     #saving the results for plotting   \n",
    "    loss_stats['train'].append(batch_loss/len(trainloader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(valloader))\n",
    "    accuracy_stats['train'].append(cum_acc/len(trainloader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(valloader))\n",
    "    \n",
    "    print(f'Epoch({e}/{num_epochs})')\n",
    "    print(f'Training loss : {batch_loss/len(trainloader)}')  \n",
    "    print(f'Training accuracy : {cum_acc/len(trainloader)}')  \n",
    "    print(f'Validation loss : {val_epoch_loss/len(valloader)}')  \n",
    "    print(f'Validation accuracy : {val_epoch_acc/len(valloader)}') \n",
    "    writer.add_scalars('CXE + MSE Loss', {'Training': np.round(batch_loss/len(trainloader), 3),\n",
    "                      'Validation': np.round(val_epoch_loss/len(valloader), 3),}, e)\n",
    "    \n",
    "writer.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-13644d5a0dc269a0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-13644d5a0dc269a0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/svtranga/Carbonate/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([8, 1, 4])) that is different to the input size (torch.Size([4, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.7089972050581127\n"
     ]
    }
   ],
   "source": [
    "#Getting testing loss\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "#model.eval()\n",
    "#with torch.no_grad():\n",
    "with torch.no_grad():\n",
    "        model_c.eval()\n",
    "        model_r.eval()\n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_acc = 0\n",
    "        #val_mse_loss = 0\n",
    "        test = 0\n",
    "        for batch, (X_test_batch, y_test_batch) in enumerate(testloader,1):\n",
    "            X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "            y_box_test = y_test_tensor[test:test+bs_valid].to(device)\n",
    "            #print(y_box_val)\n",
    "            y_test_pred = model_c(X_test_batch).squeeze()\n",
    "            y_box_pred = model_r(X_test_batch).squeeze()\n",
    "            #y_val_pred = torch.unsqueeze(y_val_pred, 0)            \n",
    "            test_loss = criterion(y_test_pred, y_test_batch)\n",
    "            test_acc = binary_acc(y_test_pred, y_test_batch) \n",
    "            #print(y_box_val)\n",
    "            #print(y_box_pred)\n",
    "            mse_loss = loss_fn(y_box_pred, torch.unsqueeze(y_box_test.float(), dim=1))\n",
    "            #print(val_loss.item(),mse_loss.item())\n",
    "            test_epoch_loss += test_loss.item() + mse_loss.item()\n",
    "            test_epoch_acc += test_acc.item()\n",
    "            test += bs_valid\n",
    "            \n",
    "        \n",
    "\n",
    "        #print(f'Epoch({e}/{num_epochs})')\n",
    "        print(f'Test loss : {test_epoch_loss/len(testloader)}')  \n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sequential model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
